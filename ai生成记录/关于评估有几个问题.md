# 1. 评估对战是谁和谁对战？
评估对战是训练中的AlphaZero模型与纯蒙特卡洛树搜索(Pure MCTS)玩家的对战。纯MCTS不使用神经网络，只依靠蒙特卡洛树搜索算法，是一个相对稳定的基准对手。这种评估方法的目的是测量神经网络是否确实提高了决策质量，如果AlphaZero的胜率超过纯MCTS，就说明神经网络的指导确实增加了价值。

# 2. 评估对战局数是否够客观？
默认的评估对战局数是10局，这确实偏少了，容易受随机性影响。在train.py的policy_evaluate函数中定义了评估局数参数n_games=10，增加到30-50局会使评估结果更稳定客观。这个参数可以在config.py中添加一个新的配置项如eval_games = 30来调整。

# 3. 从日志做模型评估是否够了？
仅从训练日志进行模型评估是不够全面的。应该考虑以下额外评估：
更多样的对手：与不同强度和风格的对手对战
人类测试：让人类玩家体验并评价模型表现
不同配置测试：测试不同MCTS模拟次数、温度参数等对表现的影响

# 4.棋盘变化：在不同尺寸棋盘上测试泛化能力
手动设计的测试局面：测试特定局面的决策质量