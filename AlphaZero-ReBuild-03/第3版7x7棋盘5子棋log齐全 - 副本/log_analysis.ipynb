{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaZero 五子棋训练分析\n",
    "\n",
    "本notebook对训练日志进行全面分析，提取关键信息并进行可视化，帮助理解训练过程和模型性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析日志文件\n",
    "log_path = '7x5_train_log_20250505_174141.txt'  # 请根据实际文件路径调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os\n",
    "\n",
    "# 设置可视化风格\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import os\n",
    "\n",
    "# 1. 检查并设置中文字体\n",
    "def set_chinese_font():\n",
    "    # 尝试使用系统自带的中文字体\n",
    "    font_paths = [\n",
    "        'C:/Windows/Fonts/simhei.ttf',  # 黑体\n",
    "        'C:/Windows/Fonts/msyh.ttc',    # 微软雅黑\n",
    "        'C:/Windows/Fonts/simkai.ttf',  # 楷体\n",
    "    ]\n",
    "    \n",
    "    # 查找第一个可用的中文字体\n",
    "    for font_path in font_paths:\n",
    "        if os.path.exists(font_path):\n",
    "            font_prop = fm.FontProperties(fname=font_path)\n",
    "            plt.rcParams['font.sans-serif'] = [font_prop.get_name()]\n",
    "            plt.rcParams['axes.unicode_minus'] = False\n",
    "            return True\n",
    "    \n",
    "    # 如果没有找到系统字体，尝试下载并使用临时字体\n",
    "    try:\n",
    "        import urllib.request\n",
    "        print(\"正在下载中文字体...\")\n",
    "        urllib.request.urlretrieve(\n",
    "            \"https://github.com/googlefonts/noto-cjk/raw/main/Sans/OTF/SimplifiedChinese/NotoSansCJKsc-Regular.otf\",\n",
    "            \"NotoSansCJKsc-Regular.otf\")\n",
    "        font_prop = fm.FontProperties(fname=\"NotoSansCJKsc-Regular.otf\")\n",
    "        plt.rcParams['font.sans-serif'] = [font_prop.get_name()]\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        return True\n",
    "    except:\n",
    "        print(\"无法自动下载中文字体，请手动安装\")\n",
    "        return False\n",
    "\n",
    "# 设置中文字体\n",
    "set_chinese_font()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 日志数据解析\n",
    "\n",
    "从训练日志中提取两类关键信息：\n",
    "1. 每批次训练详情（损失、KL散度等）\n",
    "2. 定期评估结果（胜率等）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_training_log(log_path):\n",
    "    \"\"\"解析训练日志文件，提取训练数据和评估数据\"\"\"\n",
    "    \n",
    "    # 初始化用于存储提取数据的列表\n",
    "    train_data = []\n",
    "    eval_data = []\n",
    "    \n",
    "    # 解析的正则表达式模式\n",
    "    batch_pattern = re.compile(r'训练批次: (\\d+), 当前对局长度: (\\d+)')\n",
    "    metrics_pattern = re.compile(r'kl:([\\d.]+), lr_multiplier:([\\d.]+), loss:([\\d.]+), entropy:([\\d.]+), explained_var_old:([\\d.-]+), explained_var_new:([\\d.-]+)')\n",
    "    eval_batch_pattern = re.compile(r'训练批次 (\\d+) - 开始策略评估')\n",
    "    eval_result_pattern = re.compile(r'评估对战结果 - 胜:(\\d+), 负:(\\d+), 平:(\\d+)，胜率:([\\d.]+)')\n",
    "    \n",
    "    current_batch = None\n",
    "    current_episode_len = None\n",
    "    eval_batch = None\n",
    "    \n",
    "    with open(log_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            # 匹配训练批次和对局长度\n",
    "            batch_match = batch_pattern.search(line)\n",
    "            if batch_match:\n",
    "                current_batch = int(batch_match.group(1))\n",
    "                current_episode_len = int(batch_match.group(2))\n",
    "                continue\n",
    "            \n",
    "            # 匹配训练指标数据\n",
    "            metrics_match = metrics_pattern.search(line)\n",
    "            if metrics_match and current_batch is not None:\n",
    "                kl = float(metrics_match.group(1))\n",
    "                lr_mult = float(metrics_match.group(2))\n",
    "                loss = float(metrics_match.group(3))\n",
    "                entropy = float(metrics_match.group(4))\n",
    "                exp_var_old = float(metrics_match.group(5))\n",
    "                exp_var_new = float(metrics_match.group(6))\n",
    "                \n",
    "                train_data.append({\n",
    "                    'batch': current_batch,\n",
    "                    'episode_len': current_episode_len,\n",
    "                    'kl': kl,\n",
    "                    'lr_multiplier': lr_mult,\n",
    "                    'loss': loss,\n",
    "                    'entropy': entropy,\n",
    "                    'explained_var_old': exp_var_old,\n",
    "                    'explained_var_new': exp_var_new\n",
    "                })\n",
    "                \n",
    "                current_batch = None\n",
    "                current_episode_len = None\n",
    "                continue\n",
    "            \n",
    "            # 匹配评估批次\n",
    "            eval_batch_match = eval_batch_pattern.search(line)\n",
    "            if eval_batch_match:\n",
    "                eval_batch = int(eval_batch_match.group(1))\n",
    "                continue\n",
    "                \n",
    "            # 匹配评估结果\n",
    "            eval_result_match = eval_result_pattern.search(line)\n",
    "            if eval_result_match and eval_batch is not None:\n",
    "                wins = int(eval_result_match.group(1))\n",
    "                losses = int(eval_result_match.group(2))\n",
    "                draws = int(eval_result_match.group(3))\n",
    "                win_ratio = float(eval_result_match.group(4))\n",
    "                \n",
    "                eval_data.append({\n",
    "                    'eval_batch': eval_batch,\n",
    "                    'wins': wins,\n",
    "                    'losses': losses,\n",
    "                    'draws': draws,\n",
    "                    'win_ratio': win_ratio,\n",
    "                    'total_games': wins + losses + draws\n",
    "                })\n",
    "                \n",
    "                eval_batch = None\n",
    "    \n",
    "    train_df = pd.DataFrame(train_data)\n",
    "    eval_df = pd.DataFrame(eval_data)\n",
    "    \n",
    "    return train_df, eval_df\n",
    "\n",
    "# 解析日志文件\n",
    "train_df, eval_df = parse_training_log(log_path)\n",
    "\n",
    "# 保存为CSV文件以便未来使用\n",
    "train_df.to_csv('training_metrics.csv', index=False)\n",
    "eval_df.to_csv('evaluation_metrics.csv', index=False)\n",
    "\n",
    "# 显示提取的训练数据样例\n",
    "print(f\"共提取 {len(train_df)} 条训练数据记录\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示提取的评估数据\n",
    "print(f\"共提取 {len(eval_df)} 条评估数据记录\")\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 基本训练指标分析\n",
    "\n",
    "分析训练过程中的关键指标变化趋势，包括损失、熵、KL散度等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练损失和熵趋势图\n",
    "fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('训练批次')\n",
    "ax1.set_ylabel('损失值', color=color)\n",
    "ax1.plot(train_df['batch'], train_df['loss'], color=color, marker='', linestyle='-', alpha=0.7, label='损失值')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# 创建第二个Y轴用于显示熵\n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('熵', color=color)  \n",
    "ax2.plot(train_df['batch'], train_df['entropy'], color=color, marker='', linestyle='-', alpha=0.7, label='熵')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# 添加网格线和标题\n",
    "ax1.grid(False)\n",
    "plt.title('训练过程中的损失值和熵变化趋势', fontsize=16)\n",
    "\n",
    "# 添加图例\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('loss_entropy_trend.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KL散度和学习率乘数趋势图\n",
    "fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "color = 'tab:green'\n",
    "ax1.set_xlabel('训练批次')\n",
    "ax1.set_ylabel('KL散度', color=color)\n",
    "ax1.plot(train_df['batch'], train_df['kl'], color=color, marker='', linestyle='-', alpha=0.7, label='KL散度')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# 创建第二个Y轴用于显示学习率乘数\n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:orange'\n",
    "ax2.set_ylabel('学习率乘数', color=color)  \n",
    "ax2.plot(train_df['batch'], train_df['lr_multiplier'], color=color, marker='', linestyle='-', alpha=0.7, label='学习率乘数')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# 添加网格线和标题\n",
    "ax1.grid(False)\n",
    "plt.title('训练过程中的KL散度和学习率乘数变化趋势', fontsize=16)\n",
    "\n",
    "# 添加图例\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('kl_lr_trend.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解释方差变化趋势\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "plt.plot(train_df['batch'], train_df['explained_var_old'], color='tab:purple', marker='', linestyle='-', alpha=0.7, label='旧模型解释方差')\n",
    "plt.plot(train_df['batch'], train_df['explained_var_new'], color='tab:brown', marker='', linestyle='-', alpha=0.7, label='新模型解释方差')\n",
    "\n",
    "plt.xlabel('训练批次')\n",
    "plt.ylabel('解释方差')\n",
    "plt.title('训练过程中的模型解释方差变化趋势', fontsize=16)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('explained_var_trend.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自我对弈游戏长度趋势\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "plt.plot(train_df['batch'], train_df['episode_len'], color='tab:cyan', marker='o', linestyle='-', alpha=0.7)\n",
    "\n",
    "plt.xlabel('训练批次')\n",
    "plt.ylabel('对局长度(步数)')\n",
    "plt.title('训练过程中的自我对弈游戏长度变化趋势', fontsize=16)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 添加趋势线\n",
    "z = np.polyfit(train_df['batch'], train_df['episode_len'], 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(train_df['batch'], p(train_df['batch']), \"r--\", label=f\"趋势线: {z[0]:.4f}x + {z[1]:.2f}\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('episode_length_trend.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 模型评估分析\n",
    "\n",
    "分析模型定期评估结果，包括胜率趋势、胜负结果分布等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#胜率变化趋势\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "plt.plot(eval_df['eval_batch'], eval_df['win_ratio'], color='tab:green', marker='o', linestyle='-', linewidth=2, markersize=8)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.7, label='随机水平(0.5)')\n",
    "\n",
    "plt.xlabel('评估批次')\n",
    "plt.ylabel('胜率')\n",
    "plt.title('AlphaZero vs纯MCTS对战胜率趋势', fontsize=16)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "\n",
    "# 添加注释，标记胜率最高点\n",
    "max_idx = eval_df['win_ratio'].idxmax()\n",
    "max_batch = eval_df.loc[max_idx, 'eval_batch']\n",
    "max_wr = eval_df.loc[max_idx, 'win_ratio']\n",
    "plt.annotate(f'最高胜率: {max_wr:.2f}',\n",
    "             xy=(max_batch, max_wr), xycoords='data',\n",
    "             xytext=(max_batch-50, max_wr+0.1), textcoords='data',\n",
    "             arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=.2\"), \n",
    "             fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('win_ratio_trend.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 胜负平分布堆积图\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "#堆积柱状图显示胜、负、平的分布\n",
    "eval_df.plot(x='eval_batch', y=['wins', 'draws', 'losses'], kind='bar', stacked=True, \n",
    "             color=['green', 'gray', 'red'], ax=ax, alpha=0.7)\n",
    "\n",
    "# 在同一图上添加胜率线\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(range(len(eval_df)), eval_df['win_ratio'], color='blue', marker='o', linestyle='-', linewidth=2, label='胜率')\n",
    "\n",
    "# 设置图表标题和标签\n",
    "ax.set_title('评估对战结果分布和胜率趋势', fontsize=16)\n",
    "ax.set_xlabel('评估批次')\n",
    "ax.set_ylabel('对局数量')\n",
    "ax2.set_ylabel('胜率')\n",
    "\n",
    "# 设置X轴标签为评估批次\n",
    "ax.set_xticklabels(eval_df['eval_batch'], rotation=45)\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "# 组合两个图例\n",
    "lines1, labels1 = ax.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('evaluation_results_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 关键指标相关性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练指标相关性热力图\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_matrix = train_df[['loss', 'entropy', 'kl', 'lr_multiplier', 'explained_var_new', 'episode_len']].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, fmt='.2f')\n",
    "plt.title('训练指标相关性矩阵', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_metrics_correlation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并训练和评估数据，分析一些关键指标与胜率的关系\n",
    "# 注意：这里我们需要对训练数据做一些处理，因为评估不是每批次都进行的\n",
    "\n",
    "# 创建合并后的DataFrame用于分析\n",
    "merged_data = pd.DataFrame()\n",
    "\n",
    "# 对于每个评估批次，找到最接近的训练数据点\n",
    "for _, eval_row in eval_df.iterrows():\n",
    "    eval_batch = eval_row['eval_batch']\n",
    "    \n",
    "    # 找最接近评估批次的训练数据\n",
    "    closest_train = train_df.iloc[(train_df['batch'] - eval_batch).abs().argsort()[0]]\n",
    "    \n",
    "    # 合并评估和训练数据\n",
    "    data = {\n",
    "        'batch': eval_batch,\n",
    "        'win_ratio': eval_row['win_ratio'],\n",
    "        'loss': closest_train['loss'],\n",
    "        'entropy': closest_train['entropy'],\n",
    "        'kl': closest_train['kl'],\n",
    "        'explained_var_new': closest_train['explained_var_new']\n",
    "    }\n",
    "    \n",
    "    merged_data = pd.concat([merged_data, pd.DataFrame([data])], ignore_index=True)\n",
    "\n",
    "# 计算胜率与各指标的相关系数\n",
    "correlations = {}\n",
    "for column in ['loss', 'entropy', 'kl', 'explained_var_new']:\n",
    "    correlation, p_value = stats.pearsonr(merged_data['win_ratio'], merged_data[column])\n",
    "    correlations[column] = (correlation, p_value)\n",
    "\n",
    "# 显示结果\n",
    "for metric, (corr, p_val) in correlations.items():\n",
    "    significance = \"显著\" if p_val < 0.05 else \"不显著\"\n",
    "    print(f\"胜率与{metric}的相关性: {corr:.4f} (p={p_val:.4f}, {significance})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#胜率与关键指标散点图\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "metrics = ['loss', 'entropy', 'kl', 'explained_var_new']\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "titles = ['损失值', '熵','KL散度', '解释方差']\n",
    "\n",
    "for i, (metric, color, title) in enumerate(zip(metrics, colors, titles)):\n",
    "    axes[i].scatter(merged_data[metric], merged_data['win_ratio'], color=color, alpha=0.7, s=100)\n",
    "    \n",
    "    # 添加趋势线\n",
    "    z = np.polyfit(merged_data[metric], merged_data['win_ratio'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_range = np.linspace(min(merged_data[metric]), max(merged_data[metric]), 100)\n",
    "    axes[i].plot(x_range, p(x_range), 'r--')\n",
    "    \n",
    "    # 显示相关系数\n",
    "    corr, p_val = correlations[metric]\n",
    "    axes[i].text(0.05, 0.95, f\"相关系数: {corr:.4f}\\np-value: {p_val:.4f}\", \n",
    "                transform=axes[i].transAxes, fontsize=12,\n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))\n",
    "\n",
    "    axes[i].set_xlabel(title)\n",
    "    axes[i].set_ylabel('胜率')\n",
    "    axes[i].set_title(f'胜率 vs {title}')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('win_ratio_vs_metrics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 训练进度与稳定性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算关键指标的移动平均，用于观察趋势更平滑的变化\n",
    "window_size = 10  # 移动平均窗口大小\n",
    "\n",
    "if len(train_df) > window_size:\n",
    "    train_df['loss_ma'] = train_df['loss'].rolling(window=window_size).mean()\n",
    "    train_df['entropy_ma'] = train_df['entropy'].rolling(window=window_size).mean()\n",
    "    train_df['kl_ma'] = train_df['kl'].rolling(window=window_size).mean()\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    plt.plot(train_df['batch'], train_df['loss_ma'], color='tab:red', label='损失值(移动平均)')\n",
    "    plt.plot(train_df['batch'], train_df['entropy_ma'], color='tab:blue', label='熵(移动平均)')\n",
    "    plt.plot(train_df['batch'], train_df['kl_ma'], color='tab:green', label='KL散度(移动平均)')\n",
    "\n",
    "    plt.xlabel('训练批次')\n",
    "    plt.ylabel('指标值')\n",
    "    plt.title(f'训练关键指标的{window_size}批次移动平均趋势', fontsize=16)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    #plt.legen\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('metrics_moving_average.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"训练数据点不足{window_size}个，无法计算移动平均。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算KL散度和损失的变化率，分析训练稳定性\n",
    "if len(train_df) > 1:\n",
    "    train_df['loss_change'] = train_df['loss'].pct_change() * 100  # 百分比变化\n",
    "    train_df['kl_change'] = train_df['kl'].pct_change() * 100\n",
    "\n",
    "    # 去掉第一行（因为变化率计算会产生NaN）和过大的值\n",
    "    change_df = train_df.iloc[1:].copy()\n",
    "    # 限制变化率范围，便于可视化\n",
    "    loss_upper = np.percentile(change_df['loss_change'].abs(), 95)\n",
    "    kl_upper = np.percentile(change_df['kl_change'].abs(), 95)\n",
    "    change_df.loc[change_df['loss_change'] > loss_upper, 'loss_change'] = loss_upper\n",
    "    change_df.loc[change_df['loss_change'] < -loss_upper, 'loss_change'] = -loss_upper\n",
    "    change_df.loc[change_df['kl_change'] > kl_upper, 'kl_change'] = kl_upper\n",
    "    change_df.loc[change_df['kl_change'] < -kl_upper, 'kl_change'] = -kl_upper\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel('训练批次')\n",
    "    ax1.set_ylabel('损失变化率(%)', color=color)\n",
    "    ax1.plot(change_df['batch'], change_df['loss_change'], color=color, marker='', linestyle='-', alpha=0.7)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    # 创建第二个Y轴\n",
    "    ax2 = ax1.twinx()  \n",
    "    color = 'tab:green'\n",
    "    ax2.set_ylabel('KL散度变化率(%)', color=color)  \n",
    "    ax2.plot(change_df['batch'], change_df['kl_change'], color=color, marker='', linestyle='-', alpha=0.7)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    plt.title('训练过程中损失和KL散度的变化率', fontsize=16)\n",
    "    plt.grid(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('metrics_change_rate.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 计算稳定性指标：变化率的标准差和平均绝对值\n",
    "    loss_stability = change_df['loss_change'].std()\n",
    "    kl_stability = change_df['kl_change'].std()\n",
    "    loss_avg_change = change_df['loss_change'].abs().mean()\n",
    "    kl_avg_change = change_df['kl_change'].abs().mean()\n",
    "    \n",
    "    print(f\"损失值变化率标准差: {loss_stability:.2f}%\")\n",
    "    print(f\"KL散度变化率标准差: {kl_stability:.2f}%\")\n",
    "    print(f\"损失值平均绝对变化率: {loss_avg_change:.2f}%\")\n",
    "    print(f\"KL散度平均绝对变化率: {kl_avg_change:.2f}%\")\n",
    "else:\n",
    "    print(\"训练数据点不足，无法计算变化率。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 培训性能阶段分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将整个训练过程分为多个阶段，分析各阶段的性能变化\n",
    "if len(train_df) > 50 and len(eval_df) > 3:  # 确保有足够数据点进行分段分析\n",
    "    # 定义训练阶段 (每个阶段包含相同数量的批次)\n",
    "    num_stages = min(5, len(eval_df)) # 分为5个阶段或更少\n",
    "    max_batch = train_df['batch'].max()\n",
    "    stage_size = max_batch // num_stages\n",
    "    \n",
    "    # 添加阶段标签到训练数据\n",
    "    train_df['stage'] = (train_df['batch'] - 1) // stage_size + 1\n",
    "    train_df['stage'] = train_df['stage'].clip(upper=num_stages)  # 确保不超过阶段数\n",
    "    \n",
    "    # 对于评估数据，也添加阶段标签\n",
    "    eval_df['stage'] = (eval_df['eval_batch'] - 1) // stage_size + 1\n",
    "    eval_df['stage'] = eval_df['stage'].clip(upper=num_stages)\n",
    "    \n",
    "    # 按阶段统计平均指标\n",
    "    stage_metrics = train_df.groupby('stage').agg({\n",
    "        'loss': 'mean',\n",
    "        'entropy': 'mean',\n",
    "        'kl': 'mean',\n",
    "        'explained_var_new': 'mean',\n",
    "    }).reset_index()\n",
    "    \n",
    "    # 合并评估结果\n",
    "    stage_eval = eval_df.groupby('stage')['win_ratio'].mean().reset_index()\n",
    "    stage_metrics = pd.merge(stage_metrics, stage_eval, on='stage')\n",
    "    \n",
    "    # 绘制阶段性能雷达图\n",
    "    metrics = ['loss', 'entropy', 'kl', 'explained_var_new', 'win_ratio']\n",
    "    \n",
    "    # 标准化指标值到[0,1]区间，便于比较\n",
    "    for metric in metrics:\n",
    "        if metric != 'win_ratio' and metric != 'explained_var_new':  # 这些指标越小越好\n",
    "            max_val = stage_metrics[metric].max()\n",
    "            min_val = stage_metrics[metric].min()\n",
    "            if max_val > min_val:\n",
    "                stage_metrics[f'{metric}_scaled'] = 1 - (stage_metrics[metric] - min_val) / (max_val - min_val)\n",
    "            else:\n",
    "                stage_metrics[f'{metric}_scaled'] = 0.5\n",
    "        else:  # 这些指标越大越好\n",
    "            max_val = stage_metrics[metric].max()\n",
    "            min_val = stage_metrics[metric].min()\n",
    "            if max_val > min_val:\n",
    "                stage_metrics[f'{metric}_scaled'] = (stage_metrics[metric] - min_val) / (max_val - min_val)\n",
    "            else:\n",
    "                stage_metrics[f'{metric}_scaled'] = 0.5\n",
    "    \n",
    "    # 创建雷达图\n",
    "    labels = ['损失值(反转)', '熵(反转)', 'KL散度(反转)', '解释方差', '胜率']\n",
    "    scaled_metrics = [f'{m}_scaled' for m in metrics]\n",
    "    \n",
    "    angles = np.linspace(0, 2*np.pi, len(labels), endpoint=False).tolist()\n",
    "    angles += angles[:1]  # 闭合雷达图\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))\n",
    "    \n",
    "    for i, stage in enumerate(stage_metrics['stage']):\n",
    "        values = stage_metrics.loc[i, scaled_metrics].tolist()\n",
    "        values += values[:1]  # 闭合雷达图\n",
    "        \n",
    "        ax.plot(angles, values, linewidth=2, linestyle='solid', label=f'阶段{stage}')\n",
    "        ax.fill(angles, values, alpha=0.1)\n",
    "    \n",
    "    ax.set_thetagrids(np.degrees(angles[:-1]), labels)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title('各训练阶段性能雷达图', fontsize=16)\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_stages_radar.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 表格显示各阶段原始数据\n",
    "    display(stage_metrics[['stage', 'loss', 'entropy', 'kl', 'explained_var_new', 'win_ratio']])\n",
    "else:\n",
    "    print(\"训练数据点不足，无法进行阶段分析。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 训练洞察与建议\n",
    "\n",
    "基于以上分析，我们可以得出以下洞察与建议：\n",
    "\n",
    "### 训练进度评估\n",
    "\n",
    "1. **模型收敛情况**：通过损失、熵和KL散度的下降趋势可以评估模型是否收敛。\n",
    "   \n",
    "2. **胜率表现**：通过对战纯MCTS的胜率可以直接评估模型的实战能力提升。\n",
    "\n",
    "3. **学习效率**：自适应学习率乘数的变化表明了训练的自我调节能力。\n",
    "\n",
    "### 改进建议\n",
    "\n",
    "1. **评估对战次数**：目前评估对战为10局，这个样本量偏小容易受随机性影响。建议增加到30-50局以获得更稳定的评估结果。在`config.py`中可以调整评估局数。\n",
    "\n",
    "2. **训练稳定性**：如果KL散度波动较大，可以考虑降低初始学习率或调整其上下限，提高训练稳定性。\n",
    "\n",
    "3. **训练扩展**：\n",
    "   - 考虑在更大的棋盘上训练（如8x8或10x10）\n",
    "   - 增加MCTS模拟次数以提高策略质量\n",
    "   - 尝试不同的网络结构\n",
    "\n",
    "4. **模型评估**：\n",
    "   - 增加与其他算法的对比评估（如Minimax、Alpha-Beta等）\n",
    "   - 测试在不同参数设置下模型的表现\n",
    "   - 人类测试者评估不同阶段模型的质量感受\n",
    "\n",
    "5. **数据增强**：考虑引入更丰富的数据增强策略，不仅是旋转和翻转。\n",
    "\n",
    "### 关键发现\n",
    "\n",
    "1. **自我对弈质量**：随着训练进行，自我对弈的质量通常会提高，游戏长度可能会有变化趋势，反映了策略的成熟度。\n",
    "\n",
    "2. **解释方差提升**：解释方差的提升反映了价值网络预测准确性的提高，这对MCTS搜索效率至关重要。\n",
    "\n",
    "3. **熵下降**：策略熵的下降表明模型对动作选择的确定性增强，但过早的熵下降也可能导致探索不足。\n",
    "\n",
    "根据以上分析，可以对训练参数进行针对性调整，提高模型训练效率和最终性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 结论\n",
    "\n",
    "通过对AlphaZero五子棋训练日志的全面分析，我们可以看到模型训练的完整过程和性能演变。关键结论如下：\n",
    "\n",
    "1. **训练趋势**：从损失、熵和KL散度的变化趋势来看，模型整体呈现出逐步收敛的特征。\n",
    "\n",
    "2. **模型能力**：通过与纯MCTS的对战胜率，我们可以直观地评估模型能力的提升。胜率的稳定提高表明神经网络确实提升了决策质量。\n",
    "\n",
    "3. **训练稳定性**：学习率自适应调整机制有效地维持了训练稳定性，避免了过大的策略更新。\n",
    "\n",
    "4. **关键指标关联**：解释方差与胜率的正相关表明价值网络的预测准确性对最终对弈表现有重要影响。\n",
    "\n",
    "总体而言，训练日志分析提供了丰富的信息，帮助我们理解AlphaZero训练过程中的各种现象，为进一步优化训练策略提供了重要依据。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
