'''

以下是针对 **RTX 4090D（24GB显存）** 的优化参数配置及分析，在保持高效训练的同时最大化利用显卡性能：

---

### **🚀 RTX 4090D 优化配置（24GB显存）**
```python
'''
import torch

class Config:
    def __init__(self):
        # === 硬件配置 ===
        self.use_gpu = torch.cuda.is_available()  # 4090D可稳定启用GPU加速
        
        # === 游戏配置 ===
        self.board_size = 11  # 可升级到11x11（4090D能承受）
        self.win_count = 5    # 五子棋
        
        # === 神经网络配置 ===
        self.num_res_blocks = 12     # 进一步加深模型（原8→12）
        self.num_filters = 256       # 提升特征维度（原128→256）
        
        # === 训练配置 ===
        self.batch_size = 512       # 大batch充分利用显存（24GB足够）
        self.epochs = 50            # 更多训练轮次
        self.learning_rate = 0.001  # 更低学习率配合大batch
        self.l2_const = 1e-4
        
        # === MCTS配置 ===
        self.num_simulations = 800  # 深度翻倍（原400→800）
        self.c_puct = 1.5           # 保持适度探索
        self.temp_threshold = 30    # 延长高温探索步数
        
        # === 自我对弈配置 ===
        self.num_self_play = 400    # 数据量翻倍（原200→400）
        self.num_iterations = 100   # 迭代轮次增加（原50→100）
        self.buffer_size = 500000   # 经验池扩容（原100k→500k）
        self.checkpoint_freq = 10   # 减少保存频率（每10轮存一次）
        
        # === 其他配置 ===
        self.self_play_progress = True
        self.enable_visualization = False  # 关闭可视化加速
'''
```

---

### **🔍 关键优化点（对比原4070配置）**
| 参数                | RTX 4070配置 | RTX 4090D优化配置 | 优化原因 |
|---------------------|-------------|-------------------|----------|
| **board_size**      | 7x7         | 11x11             | 4090D算力允许更大棋盘 |
| **num_res_blocks**  | 8           | 12                | 更深网络提升表达能力 |
| **num_filters**     | 128         | 256               | 匹配AlphaZero原论文配置 |
| **num_simulations** | 400         | 800               | 搜索深度翻倍，提升棋力 |
| **num_self_play**   | 200         | 400               | 更多数据减少过拟合 |
| **batch_size**      | 128         | 512               | 4090D显存24GB，可大幅提升 |

---

### **⏱️ 训练时间预估（RTX 4090D）**
- **单局MCTS时间**：~3.5秒（因搜索深度和棋盘增大）  
- **总对弈局数**：400局/轮 × 100轮 = 40,000局  
- **总MCTS时间**：40,000 × 3.5秒 ≈ **38.9小时**  
- **总训练时间（含反向传播）**：≈ **4-5天**（连续训练）  

---

### **📊 预期模型效果（11x11棋盘）**
| 指标               | 评分（10分制） | 说明 |
|--------------------|--------------|------|
| **棋力**           | 8.5-9.0      | 接近业余顶尖水平，可击败多数开源AI |
| **泛化能力**       | 8.0          | 适应复杂开局和中局战术 |
| **训练稳定性**     | 9.0          | 显存充足，几乎无崩溃风险 |

---

### **💡 灵活调整建议**
1. **如果想缩短时间（3天内）**：  
   - 降低 `num_iterations=50`，`num_simulations=600` → 总时间≈2.5天，评分8.0  
2. **如果想冲击最强模型（7天）**：  
   - 提升 `num_simulations=1200`，`num_iterations=150` → 评分9.0+  

---

### **⚠️ 注意事项**
1. **显存监控**：  
   - 4090D的24GB显存足够，但若启用可视化（`enable_visualization=True`）可能占用额外资源。  
2. **温度控制**：  
   - 长期高负载运行时建议通过 `nvidia-smi -pl 300` 限制功耗（避免过热降频）。  

---

### **🎯 总结**
- **4090D的优势**：24GB显存允许更大的Batch Size和更深的搜索，**11x11棋盘是最佳选择**。  
- **妥协方案**：若时间有限，优先降低 `num_iterations` 而非 `num_simulations`（搜索深度对棋力影响更大）。  
- **最终目标**：训练4-5天可获得接近SOTA的模型，适合比赛或论文实验。  

（若需进一步压缩时间，可考虑混合精度训练，但需代码支持FP16！）
'''